{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/logregdemo_slide1.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/logregdemo_slide2.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing\n",
    "\n",
    "Note the special processing of categorical parameters, where each category is treated as a separate parameter and assigned a value 0 or 1 depending on the category that is selected. These values are also known as dummy parameters. Pandas has a method get_dummies that converts expands categorical features into its constituent dummy parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dMaxPvA4n9W_"
   },
   "outputs": [],
   "source": [
    "# The data URI\n",
    "csv_file_uri = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "\n",
    "column_names = [\n",
    "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\",\n",
    "    \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\",\n",
    "    \"hours-per-week\", \"native-country\", \"target\"\n",
    "]\n",
    "\n",
    "data_original = pd.read_csv(csv_file_uri, names=column_names, index_col=False)\n",
    "\n",
    "USE_LABEL_ENCODER = False\n",
    "\n",
    "if USE_LABEL_ENCODER:\n",
    "\n",
    "    # Make a copy so that we always have the original data to refer to\n",
    "    data = data_original.copy(deep=True)\n",
    "\n",
    "    # Drop the US weights (don't have any value)\n",
    "    data.drop([\"fnlwgt\"], axis=1, inplace=True)\n",
    "\n",
    "    # Create a function that changes the text to a simple binary value\n",
    "    def convert_target_variable(text):\n",
    "        if text == \" <=50K\":\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    data[\"target\"] = data.target.apply(convert_target_variable)\n",
    "\n",
    "    encoded_columns = []\n",
    "    for c in data.columns:\n",
    "        if data[c].dtype == \"object\":\n",
    "            if \"{}_encoded\".format(c) not in data.columns:\n",
    "                encoder = preprocessing.LabelEncoder()\n",
    "                data[\"{}_encoded\".format(c)] = encoder.fit_transform(data[c].values)\n",
    "                encoded_columns.append(c)\n",
    "                encoder = None\n",
    "            else:\n",
    "                print(\"{}_encoded already exists\".format(c))\n",
    "\n",
    "    print(\"Dropping the encoded columns {}\".format(encoded_columns))\n",
    "    data.drop(encoded_columns, axis=1, inplace=True)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # Make a copy so that we always have the original data to refer to\n",
    "    data_pre_dummies = data_original.copy(deep=True)\n",
    "\n",
    "    # Drop the US weights (don't have any value)\n",
    "    data_pre_dummies.drop([\"fnlwgt\"], axis=1, inplace=True)\n",
    "    \n",
    "    data = pd.get_dummies(data_pre_dummies)\n",
    "\n",
    "    # Deletes the original column in this dataframe.\n",
    "    data.drop([\"target_ <=50K\"], axis=1, inplace=True)\n",
    "\n",
    "    # Rename the target\n",
    "    data.rename(columns={'target_ >50K': 'target' }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32561"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view number of data points in the dataset\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def anything(string):\n",
    "    # replace the $ with nothing\n",
    "    \n",
    "    return string.replace(\"$\",\"\")\n",
    "\n",
    "print(anything(\"$1.0\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Split into train and test sets\n",
    "\n",
    "This is the moment we can use the new, numerical, data to plug it into pretty much any classification model. First we'll convert the data to a matrix with our features - that is the data that we want to use to predict from - and an array with our labels - the target variable that indicates if someone makes more than 50k or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U8qcZVFMybnT"
   },
   "outputs": [],
   "source": [
    "feature_columns = data.columns.tolist()\n",
    "feature_columns.remove(\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Use first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "6PKvkNxwMyPN",
    "outputId": "6f68ba5a-9170-49e9-bf8e-28827170fc64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 107)\n",
      "(32561,)\n"
     ]
    }
   ],
   "source": [
    "X = data[feature_columns].values\n",
    "y = data[\"target\"].values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "RM4nGlt0NWCE",
    "outputId": "ac07d1ac-c77b-4e35-bd64-e70795ab12e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  39   13 2174    0   40    0    0    0    0    0    0    0    1    0\n",
      "    0    0    0    0    0    0    0    0    0    1    0    0    0    0\n",
      "    0    0    0    0    0    0    1    0    0    0    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    1    0    0\n",
      "    0    0    0    0    0    0    1    0    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    1    0    0]\n",
      "[[  39   13 2174    0   40    0    0    0    0    0    0    0    1    0\n",
      "     0    0    0    0    0    0    0    0    0    1    0    0    0    0\n",
      "     0    0    0    0    0    0    1    0    0    0    1    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    1    0    0\n",
      "     0    0    0    0    0    0    1    0    1    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    1    0    0]\n",
      " [  50   13    0    0   13    0    0    0    0    0    0    1    0    0\n",
      "     0    0    0    0    0    0    0    0    0    1    0    0    0    0\n",
      "     0    0    0    0    1    0    0    0    0    0    0    0    0    1\n",
      "     0    0    0    0    0    0    0    0    0    0    1    0    0    0\n",
      "     0    0    0    0    0    0    1    0    1    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    1    0    0]]\n",
      "[   52     9 15024     0    40     0     0     0     0     0     1     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     1     0     0     0     0     0     0     1     0     0     0\n",
      "     0     0     0     0     0     1     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     1     0     0\n",
      "     0     0     1     1     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     1     0     0]\n",
      "[[0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Quick tips on how to index matrices/arrays\n",
    "\n",
    "# The first ROW\n",
    "print(X[0,:])\n",
    "\n",
    "# The first TWO ROWS\n",
    "print(X[:2,:])\n",
    "\n",
    "# The last ROW\n",
    "print(X[-1,:])\n",
    "\n",
    "# The first 3 ROWS with only the last TWO COLUMNS\n",
    "print(X[:3,-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select and Configure Algorithm & Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use a model from **scikit-learn**: LogisticRegression\n",
    "\n",
    "For those interested in the [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-XhqqOU0wfJv"
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# Create linear regression object\n",
    "clf = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model on the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAGIC\n",
    "# \n",
    "# Train the model using the training sets\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expore the model - Understanding Variable Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-082f960ebaa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmean_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstd_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmax_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmin_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "mean_coef = clf.coef_[0].mean()\n",
    "std_coef = clf.coef_[0].std()\n",
    "max_coef = clf.coef_[0].max()\n",
    "min_coef = clf.coef_[0].min()\n",
    "\n",
    "# get extreme values\n",
    "extreme_values = []\n",
    "for ix, c in enumerate(feature_columns):\n",
    "    # I am only going to print the coefficients that are very extreme\n",
    "    # (i.e., close to the min/max)\n",
    "    # lets get the variables in a handy way\n",
    "    this_coef = clf.coef_[0][ix]\n",
    "    if abs((this_coef-mean_coef)/std_coef) > 1.5:\n",
    "        extreme_values.append((c,clf.coef_[0][ix]))\n",
    "        \n",
    "# Pretty print with the column names\n",
    "extreme_values.sort(key=lambda x: x[1])\n",
    "for item in extreme_values:\n",
    "    print(\"Column %-35s:%6.2f\" % (item[0], item[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                                52\n",
      "workclass                Self-emp-inc\n",
      "fnlwgt                         287927\n",
      "education                     HS-grad\n",
      "education-num                       9\n",
      "marital-status     Married-civ-spouse\n",
      "occupation            Exec-managerial\n",
      "relationship                     Wife\n",
      "race                            White\n",
      "sex                            Female\n",
      "capital-gain                    15024\n",
      "capital-loss                        0\n",
      "hours-per-week                     40\n",
      "native-country          United-States\n",
      "target                           >50K\n",
      "Name: 32560, dtype: object\n",
      "Predict its a [1]\n",
      "With a probability of 0.994521860997622\n"
     ]
    }
   ],
   "source": [
    "IX = -1\n",
    "\n",
    "# Make predictions using the testing set. \n",
    "# For now we'll use the last value of the training set.\n",
    "pred = clf.predict(X[IX,:].reshape(1,-1))\n",
    "\n",
    "# Print the data \n",
    "print(data_original.iloc[data_original.index[IX]])\n",
    "\n",
    "# and the prediction\n",
    "print(\"Predict its a {}\".format(pred))\n",
    "\n",
    "probability = clf.predict_proba(X[IX,:].reshape(1,-1))\n",
    "print(\"With a probability of {}\".format(probability[0,pred[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score against the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oNh6zR4VT71B",
    "outputId": "39d5d737-6ddb-4f3a-97fd-5e6b7232be7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has an overall accuracy of 0.8536199516099013\n"
     ]
    }
   ],
   "source": [
    "# How good is the model by evaluating it on the training set\n",
    "print(\"This model has an overall accuracy of {}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bb9b0ae46164>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# print(clf.coef_)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The average coefficient has a value of {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The max and min coefficient are {} and {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The standard deviation of the coefficients is {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "# How did the model do this? We can see the coefficients \n",
    "# for each column using \n",
    "# print(clf.coef_)\n",
    "\n",
    "print(\"The average coefficient has a value of {}\".format(clf.coef_[0].mean()))\n",
    "print(\"The max and min coefficient are {} and {}\".format(clf.coef_[0].max(), clf.coef_[0].min()))\n",
    "print(\"The standard deviation of the coefficients is {}\".format(clf.coef_[0].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_coef = clf.coef_[0].mean()\n",
    "std_coef = clf.coef_[0].std()\n",
    "max_coef = clf.coef_[0].max()\n",
    "min_coef = clf.coef_[0].min()\n",
    "\n",
    "# Pretty print with the column names\n",
    "for ix, c in enumerate(feature_columns):\n",
    "    # I am only going to print the coefficients that are very extreme\n",
    "    # (i.e., close to the min/max)\n",
    "    # lets get the variables in a handy way\n",
    "    this_coef = clf.coef_[0][ix]\n",
    "    if abs((this_coef-mean_coef)/std_coef) > 1.5:\n",
    "        print(\"Column {} is {}\".format(c, clf.coef_[0][ix]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Data-processing.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
