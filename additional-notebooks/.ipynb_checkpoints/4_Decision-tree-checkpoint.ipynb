{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing\n",
    "\n",
    "Only alter the data pre-processing code if you have completed the challenge for that section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data URI\n",
    "csv_file_uri = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "\n",
    "column_names = [\n",
    "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\",\n",
    "    \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\",\n",
    "    \"hours-per-week\", \"native-country\", \"target\"\n",
    "]\n",
    "\n",
    "\n",
    "data_original = pd.read_csv(csv_file_uri, names=column_names, index_col=False)\n",
    "\n",
    "USE_LABEL_ENCODER = False\n",
    "\n",
    "\n",
    "if USE_LABEL_ENCODER:\n",
    "\n",
    "    # Make a copy so that we always have the original data to refer to\n",
    "    data = data_original.copy(deep=True)\n",
    "\n",
    "    # Drop the US weights (don't have any value)\n",
    "    data.drop([\"fnlwgt\"], axis=1, inplace=True)\n",
    "\n",
    "    # Create a function that changes the text to a simple binary value\n",
    "    def convert_target_variable(text):\n",
    "        if text == \" <=50K\":\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    data[\"target\"] = data.target.apply(convert_target_variable)\n",
    "\n",
    "    encoded_columns = []\n",
    "    for c in data.columns:\n",
    "        if data[c].dtype == \"object\":\n",
    "            if \"{}_encoded\".format(c) not in data.columns:\n",
    "                encoder = preprocessing.LabelEncoder()\n",
    "                data[\"{}_encoded\".format(c)] = encoder.fit_transform(data[c].values)\n",
    "                encoded_columns.append(c)\n",
    "                encoder = None\n",
    "            else:\n",
    "                print(\"{}_encoded already exists\".format(c))\n",
    "\n",
    "    print(\"Dropping the encoded columns {}\".format(encoded_columns))\n",
    "    data.drop(encoded_columns, axis=1, inplace=True)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # Make a copy so that we always have the original data to refer to\n",
    "    data_pre_dummies = data_original.copy(deep=True)\n",
    "\n",
    "    # Drop the US weights (don't have any value)\n",
    "    data_pre_dummies.drop([\"fnlwgt\"], axis=1, inplace=True)\n",
    "    \n",
    "    data = pd.get_dummies(data_pre_dummies)\n",
    "\n",
    "    # Deletes the original column in this dataframe.\n",
    "    data.drop([\"target_ <=50K\"], axis=1, inplace=True)\n",
    "\n",
    "    # Rename the target\n",
    "    data.rename(columns={'target_ >50K': 'target' }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = data.columns.tolist()\n",
    "feature_columns.remove(\"target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Model: Decision Tree\n",
    "\n",
    "Scikit-learn [docs](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[feature_columns].values\n",
    "y = data.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The accuracy is {:6.2f}%\".format(clf.score(X,y)*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How did the model do this? We can see the importance \n",
    "# for each column using \n",
    "# print(clf.feature_importances_)\n",
    "\n",
    "# Pretty print with the column names\n",
    "for ix, c in enumerate(feature_columns):\n",
    "    if clf.feature_importances_[ix] > 0.0:\n",
    "        print(\"Column {} is {}\".format(c, clf.feature_importances_[ix]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Visualize the Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2822
    },
    "colab_type": "code",
    "id": "VXPpgQROiLwR",
    "outputId": "b4e2f62d-1c98-4f8f-ea05-af9fbd0ff346"
   },
   "outputs": [],
   "source": [
    "# Install dependency\n",
    "!apt install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wvMTQ4-ZTGMR",
    "outputId": "99eb6875-0298-4596-a769-2d89c37c1efc"
   },
   "outputs": [],
   "source": [
    "# Install dependency\n",
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "colab_type": "code",
    "id": "oIC00o9jX-rM",
    "outputId": "ef6e2171-fbe0-4d9b-a207-f1a315791beb"
   },
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "tree.export_graphviz(clf, out_file=\"/tmp/tree.dot\")\n",
    "with open(\"/tmp/tree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "\n",
    "graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Challenge: Add Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cross-validation to a deep (max_depth) Decision Tree and see\n",
    "# how the training and testing accuracy will diverge.\n",
    "# Why is this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training and a testing group.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# Train the model on the training set\n",
    "clf = None\n",
    "clf = tree.DecisionTreeClassifier(max_depth=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the train, test set and compare the results\n",
    "accuracy_train = clf.score(X_train, y_train)\n",
    "accuracy_test = clf.score(X_test, y_test)\n",
    "print(\"- This model training accuracy of {}\".format(accuracy_train))\n",
    "print(\"- This model testing accuracy of {}\".format(accuracy_test))\n",
    "print(\"- The ratio is {}\".format(accuracy_test/accuracy_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_train = []\n",
    "accuracies_test = []\n",
    "\n",
    "# Cross validation in a loop.\n",
    "for i in range(25):\n",
    "    \n",
    "    # Create a training and a testing group.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "    # Train the model on the training set\n",
    "    clf = None\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=5)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the train, test set and compare the results\n",
    "    accuracies_train.append(clf.score(X_train, y_train))\n",
    "    accuracies_test.append(clf.score(X_test, y_test))\n",
    "\n",
    "assert len(accuracies_train) == len(accuracies_test)\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.plot(range(len(accuracies_train)), accuracies_train, label='Train')\n",
    "plt.plot(range(len(accuracies_test)), accuracies_test, label='Test')\n",
    "plt.ylim(0.8,1.0)\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Challenge: Implement a Random Forest\n",
    "\n",
    "See notes [here](https://jakevdp.github.io/PythonDataScienceHandbook/05.08-random-forests.html#Ensembles-of-Estimators:-Random-Forests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c27cae1dc4fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create a training and a testing group.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Train the model on the training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a training and a testing group.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# Train the model on the training set\n",
    "clf = None\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the train, test set and compare the results\n",
    "accuracy_train = clf.score(X_train, y_train)\n",
    "accuracy_test = clf.score(X_test, y_test)\n",
    "print(\"- This model training accuracy of {}\".format(accuracy_train))\n",
    "print(\"- This model testing accuracy of {}\".format(accuracy_test))\n",
    "print(\"- The ratio is {}\".format(accuracy_test/accuracy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Challenges: Test different Hyper-parameters for a Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change some of the hyper-parameters and\n",
    "# see how it impacts the tree and performance\n",
    "# Hyper-parameters:\n",
    "# - max_depth\n",
    "# - n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "\n",
    "n_estimators = [25,100,500]\n",
    "max_depths = [5, 9]\n",
    "\n",
    "ctr = 1\n",
    "for ix,n_param in enumerate(n_estimators):\n",
    "    for jx,depth in enumerate(max_depths):\n",
    "        \n",
    "        accuracies_train = []\n",
    "        accuracies_test = []\n",
    "        \n",
    "        # Cross validation in a loop.\n",
    "        for i in range(5):\n",
    "\n",
    "            # Create a training and a testing group.\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "            # Train the model on the training set\n",
    "            clf = None\n",
    "            clf = RandomForestClassifier(n_estimators=n_param, max_depth=depth)\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            # Predict on the train, test set and compare the results\n",
    "            accuracies_train.append(clf.score(X_train, y_train))\n",
    "            accuracies_test.append(clf.score(X_test, y_test))\n",
    "            \n",
    "        plt.subplot(len(n_estimators),len(max_depths), ctr)\n",
    "        ctr += 1\n",
    "        assert len(accuracies_train) == len(accuracies_test)\n",
    "        plt.plot(range(len(accuracies_train)), accuracies_train, label='Train')\n",
    "        plt.plot(range(len(accuracies_test)), accuracies_test, label='Test')\n",
    "        plt.ylim(0.8,1.0)\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.title(\"n_estimators({}), depth({})\".format(n_param, depth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Challenges: Cross-validation for a Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_train = []\n",
    "accuracies_test = []\n",
    "\n",
    "# Cross validation in a loop.\n",
    "for i in range(5):\n",
    "    \n",
    "    # Create a training and a testing group.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "    # Train the model on the training set\n",
    "    clf = None\n",
    "    clf = RandomForestClassifier(n_estimators=100, max_depth=5)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the train, test set and compare the results\n",
    "    accuracies_train.append(clf.score(X_train, y_train))\n",
    "    accuracies_test.append(clf.score(X_test, y_test))\n",
    "\n",
    "assert len(accuracies_train) == len(accuracies_test)\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.plot(range(len(accuracies_train)), accuracies_train, label='Train')\n",
    "plt.plot(range(len(accuracies_test)), accuracies_test, label='Test')\n",
    "plt.ylim(0.8,1.0)\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### More reading\n",
    "\n",
    "* [BUILDING DECISION TREE ALGORITHM IN PYTHON WITH SCIKIT LEARN](http://dataaspirant.com/2017/02/01/decision-tree-algorithm-python-with-scikit-learn/)\n",
    "* [\n",
    "How To Implement The Decision Tree Algorithm From Scratch In Python](https://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Decision-tree-plot.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
