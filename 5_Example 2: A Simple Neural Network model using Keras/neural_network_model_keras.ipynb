{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model for similar problem set as the Logistic Regression example. \n",
    "\n",
    "Adapted from https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "import pandas as pd\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data URI\n",
    "csv_file_uri = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "\n",
    "column_names = [\n",
    "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\",\n",
    "    \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\",\n",
    "    \"hours-per-week\", \"native-country\", \"target\"\n",
    "]\n",
    "\n",
    "data_original = pd.read_csv(csv_file_uri, names=column_names, index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Make a copy so that we always have the original data to refer to\n",
    "data_pre_dummies = data_original.copy(deep=True)\n",
    "\n",
    "# Drop the US weights (don't have any value)\n",
    "data_pre_dummies.drop([\"fnlwgt\"], axis=1, inplace=True)\n",
    "\n",
    "data = pd.get_dummies(data_pre_dummies)\n",
    "\n",
    "# Deletes the original column in this dataframe.\n",
    "data.drop([\"target_ <=50K\"], axis=1, inplace=True)\n",
    "\n",
    "# Rename the target\n",
    "data.rename(columns={'target_ >50K': 'target' }, inplace=True)\n",
    "    \n",
    "feature_columns = data.columns.tolist()\n",
    "feature_columns.remove(\"target\")\n",
    "\n",
    "X = data[feature_columns].values\n",
    "y = data[\"target\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select and Configure Algorithm & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=107, activation='relu'))\n",
    "model.add(Dense(107, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "21815/21815 [==============================] - 2s 112us/step - loss: 1.1226 - acc: 0.8007\n",
      "Epoch 2/25\n",
      "21815/21815 [==============================] - 2s 111us/step - loss: 1.1221 - acc: 0.8017\n",
      "Epoch 3/25\n",
      "21815/21815 [==============================] - 2s 112us/step - loss: 1.1219 - acc: 0.8037\n",
      "Epoch 4/25\n",
      "21815/21815 [==============================] - 2s 108us/step - loss: 1.1209 - acc: 0.8033\n",
      "Epoch 5/25\n",
      "21815/21815 [==============================] - 2s 107us/step - loss: 1.1208 - acc: 0.8012\n",
      "Epoch 6/25\n",
      "21815/21815 [==============================] - 3s 116us/step - loss: 1.1201 - acc: 0.8022\n",
      "Epoch 7/25\n",
      "21815/21815 [==============================] - 2s 112us/step - loss: 1.1196 - acc: 0.8025\n",
      "Epoch 8/25\n",
      "21815/21815 [==============================] - 2s 110us/step - loss: 1.1204 - acc: 0.8028\n",
      "Epoch 9/25\n",
      "21815/21815 [==============================] - 2s 109us/step - loss: 1.1190 - acc: 0.8039\n",
      "Epoch 10/25\n",
      "21815/21815 [==============================] - 2s 109us/step - loss: 1.1192 - acc: 0.8029\n",
      "Epoch 11/25\n",
      "21815/21815 [==============================] - 2s 103us/step - loss: 1.1186 - acc: 0.8026\n",
      "Epoch 12/25\n",
      "21815/21815 [==============================] - 2s 105us/step - loss: 1.1190 - acc: 0.8024\n",
      "Epoch 13/25\n",
      "21815/21815 [==============================] - 2s 107us/step - loss: 1.1176 - acc: 0.8022\n",
      "Epoch 14/25\n",
      "21815/21815 [==============================] - 2s 107us/step - loss: 1.1173 - acc: 0.8022\n",
      "Epoch 15/25\n",
      "21815/21815 [==============================] - 2s 113us/step - loss: 1.1178 - acc: 0.8006\n",
      "Epoch 16/25\n",
      "21815/21815 [==============================] - 2s 107us/step - loss: 1.1175 - acc: 0.8047\n",
      "Epoch 17/25\n",
      "21815/21815 [==============================] - 2s 108us/step - loss: 1.1173 - acc: 0.8018\n",
      "Epoch 18/25\n",
      "21815/21815 [==============================] - 2s 103us/step - loss: 1.1162 - acc: 0.8035\n",
      "Epoch 19/25\n",
      "21815/21815 [==============================] - 2s 107us/step - loss: 1.1159 - acc: 0.8042\n",
      "Epoch 20/25\n",
      "21815/21815 [==============================] - 2s 109us/step - loss: 1.1158 - acc: 0.8049\n",
      "Epoch 21/25\n",
      "21815/21815 [==============================] - 2s 107us/step - loss: 1.1162 - acc: 0.8050\n",
      "Epoch 22/25\n",
      "21815/21815 [==============================] - 2s 107us/step - loss: 1.1145 - acc: 0.8045\n",
      "Epoch 23/25\n",
      "21815/21815 [==============================] - 2s 109us/step - loss: 1.1155 - acc: 0.8053\n",
      "Epoch 24/25\n",
      "21815/21815 [==============================] - 2s 108us/step - loss: 1.1150 - acc: 0.8042\n",
      "Epoch 25/25\n",
      "21815/21815 [==============================] - 2s 106us/step - loss: 1.1155 - acc: 0.8025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2978bc88>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=25, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10746/10746 [==============================] - 0s 14us/step\n",
      "\n",
      "acc: 80.45%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
